from fastapi import File, UploadFile, FastAPI, Query, HTTPException
from pathlib import Path
import hashlib
import numpy as np
import os
from keras.models import load_model
from fastapi.middleware.cors import CORSMiddleware
import csv
import tensorflow as tf
from PIL import Image
import cv2
import uvicorn
from lime import lime_image
from skimage.segmentation import mark_boundaries
from keras.models import Model
import requests

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Cho phép tất cả các origin
    allow_credentials=True,
    allow_methods=["*"],  # Cho phép tất cả các phương thức
    allow_headers=["*"]  # Cho phép tất cả các header
)

upload_folder = Path("uploads")
upload_folder.mkdir(parents=True, exist_ok=True)

explain_folder = Path("explain")
explain_folder.mkdir(parents=True, exist_ok=True)

def generate_hash(file_content):
    hash_object = hashlib.sha256()
    hash_object.update(file_content)
    return hash_object.hexdigest()

def preprocess_image(image_path, target_size=(256, 256)):
    img = Image.open(image_path)
    img = img.resize(target_size)
    x = np.array(img, dtype=np.float32)
    x = np.expand_dims(x, axis=0)
    return x

# h5
def predict_image(image_data, model_path):
    # Load model
    model = load_model(model_path, compile=False)
    # Make prediction
    prediction = model.predict(image_data)
    # Get predicted class
    predicted_class = np.argmax(prediction)
    if predicted_class == 0:
        predicted_label = (
            f"is NOT generated by AI with {100*prediction[0][predicted_class]:.2f}% confidence"
        )
    else:
        predicted_label = (
            f"is generated by AI with {100*prediction[0][predicted_class]:.2f}% confidence"
        )
    return predicted_label

def contains_human_face(image_path):
    try:
        img = cv2.imread(image_path)
        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Tải Haar Cascade cho việc nhận diện khuôn mặt
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

        # Phát hiện khuôn mặt trong ảnh
        faces = face_cascade.detectMultiScale(gray_img, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))

        return len(faces)
    except Exception as e:
        print("Error during face detection:", str(e))
        return False

async def process_and_predict(file_content, file_path):
    with open(file_path, "wb") as buffer:
        buffer.write(file_content)

    num_faces = contains_human_face(str(file_path))
    print(num_faces)
    if num_faces == 0:
        os.remove(file_path)
        return {"result": 'may not be a face!', "filepath": "", "error": "mtcnn"}
    elif num_faces > 1:
        os.remove(file_path)
        return {"result": 'may contain more than one face!', "filepath": "", "error": "mtcnn2"}
    elif num_faces == 1:
        processed_image = preprocess_image(str(file_path))
        model_path = 'models/mobilenet_new_50_12.h5'
        predicted_class = predict_image(processed_image, model_path)
        save = 0
        if predicted_class == "is generated by AI":
            save = 1
        file_path_str = str(file_path)
        if not os.path.exists('predict.csv') or file_path_str not in open('predict.csv').read():
            with open('predict.csv', mode='a', newline='') as file:
                writer = csv.writer(file, delimiter=',', quotechar='"', quoting=csv.QUOTE_MINIMAL)
                writer.writerow([file_path, save])

        return {"result": predicted_class, "filepath": f"{file_path_str}", "error": 'none'}
    else:
        os.remove(file_path)
        return {"result": 'is not a face or more than one face!', "filepath": "", "error": "mtcnn"}

@app.post("/upload_and_process")
async def upload_and_process(file: UploadFile = File(...)):
    try:
        file_content = await file.read()
        hash_filename = generate_hash(file_content)
        file_path = upload_folder / f"{hash_filename}.jpg"
        result = await process_and_predict(file_content, file_path)
        return result

    except Exception as e:
        return {"result": '', "filepath": "", "error": f"Error: {str(e)}"}

# button correct
def save_feedback_to_csv(image_path: str, feedback: int):
    rows = []
    with open('predict.csv', mode='r') as file:
        csv_reader = csv.reader(file)
        for row in csv_reader:
            while len(row) < 3:
                row.append('')
            rows.append(row)
    found = False
    for row in rows:
        if row[0] == image_path:
            row[2] = feedback
            found = True
            break

    if not found:
        new_row = [image_path, '', feedback]
        rows.append(new_row)

    with open('predict.csv', mode='w', newline='') as file:
        writer = csv.writer(file)
        writer.writerows(rows)

@app.post("/submit_feedback")
async def submit_feedback(feedback_data: dict):
    feedback = feedback_data.get("feedback")
    image_path = feedback_data.get("image_path")
    try:
        feedback = int(feedback)
        if feedback not in [0, 1]:
            return {"message": "ok"}
    except ValueError:
        return {"message": "err"}
    try:
        save_feedback_to_csv(image_path, feedback)
    except Exception as e:
        return {"message": f"err: {str(e)}"}
    return {"message": "done"}

MOBILENET = load_model("models/mobilenet_new_50_12.h5")

# mobilenet
def unwrap_model(model):
    MOBILENET = model.get_layer('MobilenetV3large')
    inp = MOBILENET.input
    out = model.get_layer('global_average_pooling2d')(MOBILENET.output)
    out = model.get_layer('dropout')(out)
    out = model.get_layer('dense')(out)
    out = model.get_layer('dense_1')(out)
    return Model(inp, out)

def hash_image_after_write(image):
    # Tạo giá trị hash cho nội dung của file và lưu ảnh
    image_content = cv2.imencode('.png', cv2.cvtColor(image, cv2.COLOR_RGB2BGR))[1].tobytes()
    hash_filename = generate_hash(image_content)
    file_path = f"explain/{hash_filename}.png"
    cv2.imwrite(str(file_path), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
    return file_path

#hàm của LIME
def LIME_explain(image_path, model):
    image = Image.open(image_path)
    image = image.resize((256,256))
    image = np.asarray(image)

    explainer = lime_image.LimeImageExplainer()
    explanation = explainer.explain_instance(image=image.astype('double'),
                                           classifier_fn=model.predict,
                                           top_labels=2,
                                           hide_color=0,
                                           num_samples=1000)
    print(explanation.top_labels[0])
    temp, mask = explanation.get_image_and_mask(label=explanation.top_labels[0],
                                              positive_only=True,
                                              num_features=20,
                                              hide_rest=False)
    marked_image = mark_boundaries(temp, mask, color=(255, 0, 0), outline_color=(0, 255, 0)).astype('uint8')
    file_path = hash_image_after_write(marked_image)
    return file_path

def GradCAM_explain(image_path, model):
    image = Image.open(image_path)
    image = image.resize((256, 256))
    image = np.asarray(image)
    preprocessed_image = np.expand_dims(image, axis=0)

    prediction = model.predict(preprocessed_image)
    predicted_class = np.argmax(prediction)

    unwrapped_model = unwrap_model(model)
    last_conv_layer = "Conv_1"
    grad_model = Model(
        inputs=unwrapped_model.inputs,
        outputs=[unwrapped_model.get_layer(last_conv_layer).output, unwrapped_model.output]
    )
    with tf.GradientTape() as tape:
        conv_output, preds = grad_model(preprocessed_image)
        loss = preds[:, predicted_class]
    grads = tape.gradient(loss, conv_output)
    weights = tf.reduce_mean(grads, axis=(1, 2), keepdims=True)
    grads *= weights
    grads = tf.reduce_sum(grads, axis=(0, 3))
    grads = tf.nn.relu(grads)
    grads /= tf.reduce_max(grads)
    grads = tf.cast(grads * 255.0, 'uint8')
    cam = np.array(Image.fromarray(grads.numpy()).resize((256, 256)))
    orig_image = image
    cam_rgb = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)
    cam_rgb_resized = cv2.resize(cam_rgb, (orig_image.shape[1], orig_image.shape[0]))
    alpha = 0.5
    overlay = orig_image.copy()
    cv2.addWeighted(cam_rgb_resized, alpha, overlay, 1 - alpha, 0, overlay)
    file_path = hash_image_after_write(overlay)
    return file_path

@app.get("/explain")
async def explain(file_path: str = Query(..., title="File Path", description="Path to the file")):
    try:
        base_path = r"C:\Users\HP\PycharmProjects\Server"
        file_path_lime = LIME_explain(file_path, MOBILENET)
        file_path_gradcam = GradCAM_explain(file_path, MOBILENET)
        file_path_lime_new = os.path.join(base_path, file_path_lime)
        file_path_gradcam_new = os.path.join(base_path, file_path_gradcam)
        # print(file_path_lime)
        # print(file_path_gradcam)
        return {"file_path_lime": file_path_lime_new, "file_path_gradcam": file_path_gradcam_new}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

def get_filename(response):
    h = hashlib.sha256()
    h.update(response.content)
    checksum = h.hexdigest()
    filename = os.path.join("url_images", f"{checksum}.jpg")
    return filename


def save_image(response, filename):
    with open(filename, "wb") as f:
        f.write(response.content)

from fastapi.responses import FileResponse

@app.get("/predict_url")
async def predict_url(url: str):
    try:
        print(f"URL: {url}")
        response = requests.get(url)
        response.raise_for_status()

        filename = get_filename(response)
        save_image(response, filename)

        # Prepend the path to filename
        server_path = r"C:\Users\HP\PycharmProjects\Server"
        full_filename = os.path.join(server_path, filename)

        # Test if can open file and return
        with open(full_filename, "rb") as f:
            content = f.read()

        return FileResponse(full_filename, media_type="image/jpeg")
        # return {"url_image": full_filename}
    except requests.RequestException as e:
        raise HTTPException(status_code=500, detail=f"Error fetching image from URL: {str(e)}")



if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)